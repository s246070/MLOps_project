steps:
  # Step 1: Build the FastAPI Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - 'gcr.io/$PROJECT_ID/titanic-inference-api:$SHORT_SHA'
      - '-t'
      - 'gcr.io/$PROJECT_ID/titanic-inference-api:latest'
      - '-f'
      - 'dockerfiles/api.dockerfile'
      - '.'

  # Step 2: Push the image to Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - 'gcr.io/$PROJECT_ID/titanic-inference-api:$SHORT_SHA'

  # Step 3: Deploy to Cloud Run
  - name: 'gcr.io/cloud-builders/run'
    args:
      - 'deploy'
      - 'titanic-inference-api'
      - '--image'
      - 'gcr.io/$PROJECT_ID/titanic-inference-api:$SHORT_SHA'
      - '--region'
      - 'us'
      - '--platform'
      - 'managed'
      - '--memory'
      - '2Gi'
      - '--cpu'
      - '2'
      - '--timeout'
      - '300'
      - '--service-account'
      - 'cloud-run-api@$PROJECT_ID.iam.gserviceaccount.com'
      - '--allow-unauthenticated'
      - '--set-env-vars'
      - 'MODEL_BUCKET=mlops-project-models,MODEL_BLOB=modelweights.pkl'

images:
  - 'gcr.io/$PROJECT_ID/titanic-inference-api:$SHORT_SHA'
  - 'gcr.io/$PROJECT_ID/titanic-inference-api:latest'

options:
  machineType: E2_HIGHCPU_8
  logging: CLOUD_LOGGING_ONLY

timeout: '1800s'
